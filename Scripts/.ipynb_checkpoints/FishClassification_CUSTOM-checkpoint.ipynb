{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4km0ReLe1Dtr",
    "outputId": "95551279-0348-4a3e-8302-c633ac072e41"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-18 20:54:36.085788: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import os\n",
    "from random import shuffle\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# for gpu in gpus:\n",
    "#     tf.config.experimental.set_memory_growth(gpu, True)\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/fish_class\n",
      "Data\t\t\t\t\t a-large-scale-fish-dataset.zip\n",
      "ENEL645_FinalProject_FishClassification  training_1\n",
      "Model\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/root/fish_class')\n",
    "data_directory = os.getcwd()\n",
    "print(data_directory)\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Bym740s1nlG"
   },
   "source": [
    "1. Loading Data and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0HFteFhy9SoO"
   },
   "outputs": [],
   "source": [
    "# 20% Validation Set, 80% Training Set\n",
    "# Input data is balanced across the number of fish classes\n",
    "train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input, # Preprocessing function\n",
    "    validation_split=0.2 \n",
    ")\n",
    "\n",
    "test_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input # Preprocessing function\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "YCJxA9xS-94l",
    "outputId": "5aa0cea5-32f3-46c3-9310-cb737a003196"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7211 images belonging to 9 classes.\n",
      "Found 1801 images belonging to 9 classes.\n",
      "Found 430 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "# Shuffle = True randomly selects images from a random directory/class to meet the streaming batch size and send to the model for training\n",
    "# Instead of flow_from_directory, the following article: https://www.kaggle.com/pavfedotov/fish-classifier-efficientnet-acc-100, uses flow_from_dataframe\n",
    "# which simply contains the list of all image paths in directory and the corresponding class label, we can pivot to this method if it is difficult\n",
    "# to visualize results, but the method below is actually more efficient...\n",
    "train_images = train_generator.flow_from_directory(\n",
    "    directory= './Data/Train_Val',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_images = train_generator.flow_from_directory(\n",
    "    directory= './Data/Train_Val',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='validation' # Will only take 20% of the total data as the validation data\n",
    ")\n",
    "\n",
    "test_images = test_generator.flow_from_directory(\n",
    "    directory= './Data/Test',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0gM0NQ-wBJit",
    "outputId": "59e36998-f2ad-4241-dbdb-c3449823efd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training image shape: (224, 224, 3)\n",
      "Validation image shape: (224, 224, 3)\n",
      "Test image shape: (224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training image shape:\", train_images.image_shape)\n",
    "print(\"Validation image shape:\", val_images.image_shape)\n",
    "print(\"Test image shape:\", test_images.image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HpBab0rRIkjx",
    "outputId": "d83e7d17-01df-4b71-b7eb-657a4630f026"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Black Sea Sprat': 0,\n",
       " 'Gilt-Head Bream': 1,\n",
       " 'Hourse Mackerel': 2,\n",
       " 'Red Mullet': 3,\n",
       " 'Red Sea Bream': 4,\n",
       " 'Sea Bass': 5,\n",
       " 'Shrimp': 6,\n",
       " 'Striped Red Mullet': 7,\n",
       " 'Trout': 8}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zpssP4gHIrLE",
    "outputId": "1bc788b9-dcea-4e00-b67f-19eb3a0c5bca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Black Sea Sprat': 0,\n",
       " 'Gilt-Head Bream': 1,\n",
       " 'Hourse Mackerel': 2,\n",
       " 'Red Mullet': 3,\n",
       " 'Red Sea Bream': 4,\n",
       " 'Sea Bass': 5,\n",
       " 'Shrimp': 6,\n",
       " 'Striped Red Mullet': 7,\n",
       " 'Trout': 8}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_images.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WvNpGFsaNiRS",
    "outputId": "d75e9cf6-0dcb-4c33-9dfc-757692f120e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Black Sea Sprat': 0,\n",
       " 'Gilt Head Bream': 1,\n",
       " 'Horse Mackerel': 2,\n",
       " 'Red Mullet': 3,\n",
       " 'Red Sea Bream': 4,\n",
       " 'Sea Bass': 5,\n",
       " 'Shrimp': 6,\n",
       " 'Striped Red Mullet': 7,\n",
       " 'Trout': 8}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "RKpgdmcbw7ZS"
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, Input\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y8tJFnmZxE_Q"
   },
   "source": [
    "2. Defining VGG16 (CNN) Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pB_UJG23NlUj",
    "outputId": "973be7af-8041-4b27-a8e0-8862d2252ca3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-18 21:07:55.734846: W tensorflow/core/common_runtime/bfc_allocator.cc:433] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.50GiB (rounded to 1614938112)requested by op Add\n",
      "Current allocation summary follows.\n",
      "2022-03-18 21:07:55.734926: I tensorflow/core/common_runtime/bfc_allocator.cc:972] BFCAllocator dump for GPU_0_bfc\n",
      "2022-03-18 21:07:55.734948: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (256): \tTotal Chunks: 42, Chunks in use: 42. 10.5KiB allocated for chunks. 10.5KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2022-03-18 21:07:55.734962: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (512): \tTotal Chunks: 4, Chunks in use: 4. 2.0KiB allocated for chunks. 2.0KiB in use in bin. 2.0KiB client-requested in use in bin.\n",
      "2022-03-18 21:07:55.734975: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (1024): \tTotal Chunks: 7, Chunks in use: 7. 7.2KiB allocated for chunks. 7.2KiB in use in bin. 7.0KiB client-requested in use in bin.\n",
      "2022-03-18 21:07:55.734988: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (2048): \tTotal Chunks: 2, Chunks in use: 2. 7.0KiB allocated for chunks. 7.0KiB in use in bin. 6.8KiB client-requested in use in bin.\n",
      "2022-03-18 21:07:55.735002: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (4096): \tTotal Chunks: 4, Chunks in use: 2. 27.2KiB allocated for chunks. 13.5KiB in use in bin. 13.5KiB client-requested in use in bin.\n",
      "2022-03-18 21:07:55.735016: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (8192): \tTotal Chunks: 7, Chunks in use: 7. 81.8KiB allocated for chunks. 81.8KiB in use in bin. 81.0KiB client-requested in use in bin.\n",
      "2022-03-18 21:07:55.735028: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-03-18 21:07:55.735041: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (32768): \tTotal Chunks: 1, Chunks in use: 0. 39.5KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-03-18 21:07:55.735054: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-03-18 21:07:55.735073: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-03-18 21:07:55.735095: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (262144): \tTotal Chunks: 3, Chunks in use: 3. 1.18MiB allocated for chunks. 1.18MiB in use in bin. 768.0KiB client-requested in use in bin.\n",
      "2022-03-18 21:07:55.735116: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-03-18 21:07:55.735130: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-03-18 21:07:55.735148: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-03-18 21:07:55.735166: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-03-18 21:07:55.735183: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-03-18 21:07:55.735201: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-03-18 21:07:55.735220: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-03-18 21:07:55.735238: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-03-18 21:07:55.735258: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-03-18 21:07:55.735281: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (268435456): \tTotal Chunks: 9, Chunks in use: 5. 10.37GiB allocated for chunks. 7.52GiB in use in bin. 7.52GiB client-requested in use in bin.\n",
      "2022-03-18 21:07:55.735301: I tensorflow/core/common_runtime/bfc_allocator.cc:995] Bin for 1.50GiB was 256.00MiB, Chunk State: \n",
      "2022-03-18 21:07:55.735335: I tensorflow/core/common_runtime/bfc_allocator.cc:1001]   Size: 507.52MiB | Requested Size: 4B | in_use: 0 | bin_num: 20, prev:   Size: 13.5KiB | Requested Size: 13.5KiB | in_use: 1 | bin_num: -1\n",
      "2022-03-18 21:07:55.735364: I tensorflow/core/common_runtime/bfc_allocator.cc:1001]   Size: 507.88MiB | Requested Size: 192.52MiB | in_use: 0 | bin_num: 20, prev:   Size: 1.50GiB | Requested Size: 1.50GiB | in_use: 1 | bin_num: -1\n",
      "2022-03-18 21:07:55.735385: I tensorflow/core/common_runtime/bfc_allocator.cc:1001]   Size: 891.46MiB | Requested Size: 13.5KiB | in_use: 0 | bin_num: 20, prev:   Size: 1.50GiB | Requested Size: 1.50GiB | in_use: 1 | bin_num: -1\n",
      "2022-03-18 21:07:55.735409: I tensorflow/core/common_runtime/bfc_allocator.cc:1001]   Size: 1015.75MiB | Requested Size: 324B | in_use: 0 | bin_num: 20, prev:   Size: 1.50GiB | Requested Size: 1.50GiB | in_use: 1 | bin_num: -1\n",
      "2022-03-18 21:07:55.735424: I tensorflow/core/common_runtime/bfc_allocator.cc:1008] Next region of size 1048576\n",
      "2022-03-18 21:07:55.735446: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1203ae0000 of size 1280 next 1\n",
      "2022-03-18 21:07:55.735463: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1203ae0500 of size 256 next 5\n",
      "2022-03-18 21:07:55.735483: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1203ae0600 of size 256 next 8\n",
      "2022-03-18 21:07:55.735499: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1203ae0700 of size 256 next 10\n",
      "2022-03-18 21:07:55.735516: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1203ae0800 of size 256 next 11\n",
      "2022-03-18 21:07:55.735532: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1203ae0900 of size 256 next 9\n",
      "2022-03-18 21:07:55.735552: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1203ae0a00 of size 256 next 14\n",
      "2022-03-18 21:07:55.735568: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1203ae0b00 of size 256 next 15\n",
      "2022-03-18 21:07:55.735587: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1203ae0c00 of size 512 next 18\n",
      "2022-03-18 21:07:55.735603: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1203ae0e00 of size 256 next 21\n",
      "2022-03-18 21:07:55.735665: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1203ae0f00 of size 256 next 22\n",
      "2022-03-18 21:07:55.735691: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1203ae1000 of size 256 next 27\n",
      "2022-03-18 21:07:55.735709: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1203ae1100 of size 256 next 28\n",
      "2022-03-18 21:07:55.735725: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1203ae1200 of size 256 next 2\n",
      "2022-03-18 21:07:55.735740: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1203ae1300 of size 256 next 3\n",
      "2022-03-18 21:07:55.735751: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1203ae1400 of size 256 next 4\n",
      "2022-03-18 21:07:55.735769: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1203ae1500 of size 1024 next 20\n",
      "2022-03-18 21:07:55.735789: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1203ae1900 of size 1024 next 25\n",
      "2022-03-18 21:07:55.735805: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1203ae1d00 of size 256 next 30\n",
      "2022-03-18 21:07:55.735821: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1203ae1e00 of size 256 next 32\n",
      "2022-03-18 21:07:55.735839: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1203ae1f00 of size 256 next 33\n",
      "2022-03-18 21:07:55.735856: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1203ae2000 of size 256 next 34\n",
      "2022-03-18 21:07:55.735874: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1203ae2100 of size 256 next 35\n",
      "2022-03-18 21:07:55.735891: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1203ae2200 of size 256 next 36\n",
      "2022-03-18 21:07:55.735908: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1203ae2300 of size 256 next 6\n",
      "2022-03-18 21:07:55.735926: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1203ae2400 of size 3584 next 7\n",
      "2022-03-18 21:07:55.735945: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1203ae3200 of size 256 next 37\n",
      "2022-03-18 21:07:55.735960: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1203ae3300 of size 256 next 38\n",
      "2022-03-18 21:07:55.735976: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1203ae3400 of size 256 next 39\n",
      "2022-03-18 21:07:55.735994: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1203ae3500 of size 256 next 40\n",
      "2022-03-18 21:07:55.736011: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1203ae3600 of size 256 next 41\n",
      "2022-03-18 21:07:55.736029: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1203ae3700 of size 512 next 42\n",
      "2022-03-18 21:07:55.736046: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1203ae3900 of size 1024 next 44\n",
      "2022-03-18 21:07:55.736064: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1203ae3d00 of size 1024 next 45\n",
      "2022-03-18 21:07:55.736081: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1203ae4100 of size 9984 next 13\n",
      "2022-03-18 21:07:55.736099: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1203ae6800 of size 6912 next 12\n",
      "2022-03-18 21:07:55.736117: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1203ae8300 of size 13824 next 17\n",
      "2022-03-18 21:07:55.736137: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1203aeb900 of size 13824 next 16\n",
      "2022-03-18 21:07:55.736152: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1203aeef00 of size 9216 next 31\n",
      "2022-03-18 21:07:55.736169: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1203af1300 of size 515072 next 29\n",
      "2022-03-18 21:07:55.736188: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1203b6ef00 of size 463104 next 18446744073709551615\n",
      "2022-03-18 21:07:55.736207: I tensorflow/core/common_runtime/bfc_allocator.cc:1008] Next region of size 2147483648\n",
      "2022-03-18 21:07:55.736226: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1203be0000 of size 1614938112 next 43\n",
      "2022-03-18 21:07:55.736245: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1264000000 of size 256 next 46\n",
      "2022-03-18 21:07:55.736263: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1264000100 of size 13824 next 47\n",
      "2022-03-18 21:07:55.736280: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1264003700 of size 512 next 48\n",
      "2022-03-18 21:07:55.736297: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1264003900 of size 1024 next 50\n",
      "2022-03-18 21:07:55.736316: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1264003d00 of size 262144 next 51\n",
      "2022-03-18 21:07:55.736335: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1264043d00 of size 1024 next 52\n",
      "2022-03-18 21:07:55.736355: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1264044100 of size 9216 next 53\n",
      "2022-03-18 21:07:55.736371: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1264046500 of size 256 next 54\n",
      "2022-03-18 21:07:55.736390: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1264046600 of size 256 next 55\n",
      "2022-03-18 21:07:55.736408: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1264046700 of size 256 next 56\n",
      "2022-03-18 21:07:55.736428: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1264046800 of size 256 next 57\n",
      "2022-03-18 21:07:55.736446: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1264046900 of size 256 next 58\n",
      "2022-03-18 21:07:55.736466: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1264046a00 of size 256 next 59\n",
      "2022-03-18 21:07:55.736481: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1264046b00 of size 256 next 60\n",
      "2022-03-18 21:07:55.736501: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1264046c00 of size 256 next 61\n",
      "2022-03-18 21:07:55.736519: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1264046d00 of size 256 next 62\n",
      "2022-03-18 21:07:55.736535: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1264046e00 of size 256 next 63\n",
      "2022-03-18 21:07:55.736552: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1264046f00 of size 256 next 85\n",
      "2022-03-18 21:07:55.736570: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1264047000 of size 256 next 88\n",
      "2022-03-18 21:07:55.736591: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1264047100 of size 256 next 70\n",
      "2022-03-18 21:07:55.736608: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1264047200 of size 512 next 72\n",
      "2022-03-18 21:07:55.736647: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1264047400 of size 256 next 91\n",
      "2022-03-18 21:07:55.736672: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] Free  at 1264047500 of size 7168 next 89\n",
      "2022-03-18 21:07:55.736692: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1264049100 of size 3584 next 73\n",
      "2022-03-18 21:07:55.736710: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] Free  at 1264049f00 of size 6912 next 86\n",
      "2022-03-18 21:07:55.736729: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 126404ba00 of size 6912 next 65\n",
      "2022-03-18 21:07:55.736751: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] Free  at 126404d500 of size 40448 next 81\n",
      "2022-03-18 21:07:55.736764: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1264057300 of size 256 next 77\n",
      "2022-03-18 21:07:55.736781: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1264057400 of size 13824 next 78\n",
      "2022-03-18 21:07:55.736799: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] Free  at 126405aa00 of size 532174336 next 18446744073709551615\n",
      "2022-03-18 21:07:55.736817: I tensorflow/core/common_runtime/bfc_allocator.cc:1008] Next region of size 2147483648\n",
      "2022-03-18 21:07:55.736837: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1283be0000 of size 1614938112 next 49\n",
      "2022-03-18 21:07:55.736858: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] Free  at 12e4000000 of size 532545536 next 18446744073709551615\n",
      "2022-03-18 21:07:55.736873: I tensorflow/core/common_runtime/bfc_allocator.cc:1008] Next region of size 4294967296\n",
      "2022-03-18 21:07:55.736892: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1303be0000 of size 1614938112 next 26\n",
      "2022-03-18 21:07:55.736910: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1364000000 of size 1614938112 next 79\n",
      "2022-03-18 21:07:55.736928: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] Free  at 13c4420000 of size 1065091072 next 18446744073709551615\n",
      "2022-03-18 21:07:55.736945: I tensorflow/core/common_runtime/bfc_allocator.cc:1008] Next region of size 2549701632\n",
      "2022-03-18 21:07:55.736962: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 1407260000 of size 1614938112 next 83\n",
      "2022-03-18 21:07:55.736979: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] Free  at 1467680000 of size 934763520 next 18446744073709551615\n",
      "2022-03-18 21:07:55.736998: I tensorflow/core/common_runtime/bfc_allocator.cc:1033]      Summary of in-use Chunks by size: \n",
      "2022-03-18 21:07:55.737022: I tensorflow/core/common_runtime/bfc_allocator.cc:1036] 42 Chunks of size 256 totalling 10.5KiB\n",
      "2022-03-18 21:07:55.737041: I tensorflow/core/common_runtime/bfc_allocator.cc:1036] 4 Chunks of size 512 totalling 2.0KiB\n",
      "2022-03-18 21:07:55.737058: I tensorflow/core/common_runtime/bfc_allocator.cc:1036] 6 Chunks of size 1024 totalling 6.0KiB\n",
      "2022-03-18 21:07:55.737078: I tensorflow/core/common_runtime/bfc_allocator.cc:1036] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2022-03-18 21:07:55.737099: I tensorflow/core/common_runtime/bfc_allocator.cc:1036] 2 Chunks of size 3584 totalling 7.0KiB\n",
      "2022-03-18 21:07:55.737111: I tensorflow/core/common_runtime/bfc_allocator.cc:1036] 2 Chunks of size 6912 totalling 13.5KiB\n",
      "2022-03-18 21:07:55.737123: I tensorflow/core/common_runtime/bfc_allocator.cc:1036] 2 Chunks of size 9216 totalling 18.0KiB\n",
      "2022-03-18 21:07:55.737143: I tensorflow/core/common_runtime/bfc_allocator.cc:1036] 1 Chunks of size 9984 totalling 9.8KiB\n",
      "2022-03-18 21:07:55.737160: I tensorflow/core/common_runtime/bfc_allocator.cc:1036] 4 Chunks of size 13824 totalling 54.0KiB\n",
      "2022-03-18 21:07:55.737180: I tensorflow/core/common_runtime/bfc_allocator.cc:1036] 1 Chunks of size 262144 totalling 256.0KiB\n",
      "2022-03-18 21:07:55.737199: I tensorflow/core/common_runtime/bfc_allocator.cc:1036] 1 Chunks of size 463104 totalling 452.2KiB\n",
      "2022-03-18 21:07:55.737208: I tensorflow/core/common_runtime/bfc_allocator.cc:1036] 1 Chunks of size 515072 totalling 503.0KiB\n",
      "2022-03-18 21:07:55.737230: I tensorflow/core/common_runtime/bfc_allocator.cc:1036] 5 Chunks of size 1614938112 totalling 7.52GiB\n",
      "2022-03-18 21:07:55.737243: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Sum Total of in-use chunks: 7.52GiB\n",
      "2022-03-18 21:07:55.737262: I tensorflow/core/common_runtime/bfc_allocator.cc:1042] total_region_allocated_bytes_: 11140684800 memory_limit_: 11140684864 available bytes: 64 curr_region_allocation_bytes_: 17179869184\n",
      "2022-03-18 21:07:55.737288: I tensorflow/core/common_runtime/bfc_allocator.cc:1048] Stats: \n",
      "Limit:                     11140684864\n",
      "InUse:                      8076055808\n",
      "MaxInUse:                   8679763456\n",
      "NumAllocs:                       74829\n",
      "MaxAllocSize:               2182610944\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2022-03-18 21:07:55.737318: W tensorflow/core/common_runtime/bfc_allocator.cc:441] ***************____***************____******************************_________***************________\n",
      "2022-03-18 21:07:55.737374: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at cwise_ops_common.h:128 : Resource exhausted: OOM when allocating tensor with shape[1577088,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[1577088,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Add]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9408/3104215163.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yes/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[1;32m    952\u001b[0m                                                 input_list)\n\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yes/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1088\u001b[0m           layer=self, inputs=inputs, build_graph=True, training=training_value):\n\u001b[1;32m   1089\u001b[0m         \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m         outputs = self._keras_tensor_symbolic_call(\n\u001b[0m\u001b[1;32m   1091\u001b[0m             inputs, input_masks, args, kwargs)\n\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yes/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yes/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    860\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yes/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2708\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2709\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2710\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2711\u001b[0m       \u001b[0;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2712\u001b[0m       \u001b[0;31m# shape is stored since user defined build functions may not be calling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yes/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m   1183\u001b[0m                        'should be defined. Found `None`.')\n\u001b[1;32m   1184\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInputSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlast_dim\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1185\u001b[0;31m     self.kernel = self.add_weight(\n\u001b[0m\u001b[1;32m   1186\u001b[0m         \u001b[0;34m'kernel'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlast_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yes/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[1;32m    621\u001b[0m         \u001b[0mcaching_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m     variable = self._add_variable_with_custom_getter(\n\u001b[0m\u001b[1;32m    624\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m         \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yes/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[0;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[1;32m    803\u001b[0m         \u001b[0;31m# \"best effort\" to set the initializer with the highest restore UID.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0minitializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint_initializer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 805\u001b[0;31m     new_variable = getter(\n\u001b[0m\u001b[1;32m    806\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m         \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yes/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36mmake_variable\u001b[0;34m(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner)\u001b[0m\n\u001b[1;32m    128\u001b[0m   \u001b[0;31m# can remove the V1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m   \u001b[0mvariable_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m   return tf_variables.VariableV1(\n\u001b[0m\u001b[1;32m    131\u001b[0m       \u001b[0minitial_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yes/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariableV1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yes/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m_variable_v1_call\u001b[0;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maggregation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m       \u001b[0maggregation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariableAggregation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNONE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m     return previous_getter(\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0minitial_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yes/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m                         shape=None):\n\u001b[1;32m    198\u001b[0m     \u001b[0;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m     \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_variable_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m       \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_getter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yes/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mdefault_variable_creator\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m   2602\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0muse_resource\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2603\u001b[0m     \u001b[0mdistribute_strategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"distribute_strategy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2604\u001b[0;31m     return resource_variable_ops.ResourceVariable(\n\u001b[0m\u001b[1;32m   2605\u001b[0m         \u001b[0minitial_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2606\u001b[0m         \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yes/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yes/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m   1572\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_from_proto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimport_scope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimport_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1573\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1574\u001b[0;31m       self._init_from_args(\n\u001b[0m\u001b[1;32m   1575\u001b[0m           \u001b[0minitial_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1576\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yes/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[0;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\u001b[0m\n\u001b[1;32m   1710\u001b[0m           \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initializer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minit_from_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1712\u001b[0;31m               \u001b[0minitial_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1713\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCheckpointInitialValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1714\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_initialize_trackable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yes/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/keras/initializers/initializers_v2.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, shape, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    407\u001b[0m       \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAdditional\u001b[0m \u001b[0mkeyword\u001b[0m \u001b[0marguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m     \"\"\"\n\u001b[0;32m--> 409\u001b[0;31m     return super(VarianceScaling, self).__call__(\n\u001b[0m\u001b[1;32m    410\u001b[0m         shape, dtype=_get_dtype(dtype), **kwargs)\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yes/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/ops/init_ops_v2.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, shape, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m       \u001b[0mlimit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_random_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yes/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/ops/init_ops_v2.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(self, shape, minval, maxval, dtype)\u001b[0m\n\u001b[1;32m   1079\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m       \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m     return op(\n\u001b[0m\u001b[1;32m   1082\u001b[0m         shape=shape, minval=minval, maxval=maxval, dtype=dtype, seed=self.seed)\n\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yes/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yes/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/ops/random_ops.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(shape, minval, maxval, dtype, seed, name)\u001b[0m\n\u001b[1;32m    306\u001b[0m           \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmaxval\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mminval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m     \u001b[0;31m# TODO(b/132092188): C++ shape inference inside functional ops does not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;31m# cross FuncGraph boundaries since that information is only available in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yes/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    325\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yes/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6860\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6861\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6862\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6863\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yes/envs/tensorflow/lib/python3.9/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[1577088,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Add]"
     ]
    }
   ],
   "source": [
    "# Original VGG16 implementation, seems not be well suited for this dataset\n",
    "# input = Input(shape =(224,224,3))\n",
    "# x = Conv2D (filters =64, kernel_size =3, padding ='same', activation='relu')(input)\n",
    "# x = Conv2D (filters =64, kernel_size =3, padding ='same', activation='relu')(x)\n",
    "# x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
    "# x = Conv2D (filters =128, kernel_size =3, padding ='same', activation='relu')(x)\n",
    "# x = Conv2D (filters =128, kernel_size =3, padding ='same', activation='relu')(x)\n",
    "# x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
    "# x = Conv2D (filters =256, kernel_size =3, padding ='same', activation='relu')(x) \n",
    "# x = Conv2D (filters =256, kernel_size =3, padding ='same', activation='relu')(x) \n",
    "# x = Conv2D (filters =256, kernel_size =3, padding ='same', activation='relu')(x) \n",
    "# x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
    "# x = Conv2D (filters =512, kernel_size =3, padding ='same', activation='relu')(x)\n",
    "# x = Conv2D (filters =512, kernel_size =3, padding ='same', activation='relu')(x)\n",
    "# x = Conv2D (filters =512, kernel_size =3, padding ='same', activation='relu')(x)\n",
    "# x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
    "# x = Conv2D (filters =512, kernel_size =3, padding ='same', activation='relu')(x)\n",
    "# x = Conv2D (filters =512, kernel_size =3, padding ='same', activation='relu')(x)\n",
    "# x = Conv2D (filters =512, kernel_size =3, padding ='same', activation='relu')(x)\n",
    "# x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
    "# x = Flatten()(x) \n",
    "# x = Dense(units = 4096, activation ='relu')(x) \n",
    "# x = Dense(units = 4096, activation ='relu')(x) \n",
    "# output = Dense(units = 9, activation ='softmax')(x)\n",
    "# model = Model (inputs=input, outputs =output)\n",
    "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) # Uses default LR or 0.001\n",
    "\n",
    "\n",
    "# THIS WORKS FOR SOME REASON!\n",
    "# Shallower model, simply halving image size while doubling filters, has more parameteres but performs way better in less time\n",
    "input = Input(shape =(224,224,3))\n",
    "x = Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(input)\n",
    "x = MaxPool2D(2,2)(x)\n",
    "x = Conv2D(filters=64, kernel_size=(3, 3), activation='relu')(input)\n",
    "x = MaxPool2D(2,2)(x)\n",
    "x = Conv2D(filters=128, kernel_size=(3, 3), activation='relu')(input)\n",
    "x = MaxPool2D(2,2)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "output = Dense(9, activation='softmax')(x)\n",
    "model = Model (inputs=input, outputs =output)\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7jg-ixS3xn0e"
   },
   "source": [
    "3. Defining Schedulers and Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "sKzgcZxvxnf1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 5) # Fine tune\n",
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "monitor = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, monitor='val_loss',\n",
    "                                             verbose=1,save_best_only=True,\n",
    "                                             save_weights_only=True,\n",
    "                                             mode='min') # Only saves the best model (so far) in terms of min validation loss\n",
    "# # Learning rate schedule\n",
    "# def scheduler(epoch, lr): # Fine tune\n",
    "#     if epoch%10 == 0: # Occurs on 10, 20, 30, 40, 50\n",
    "#         lr = lr/2 \n",
    "#     return lr\n",
    "\n",
    "# lr_schedule = tf.keras.callbacks.LearningRateScheduler(scheduler,verbose = 1)\n",
    "lr_schedule = ReduceLROnPlateau(monitor='val_loss', mode='min', factor=0.1, patience=5, min_lr=0.000001, verbose=1)\n",
    "callbacks = [early_stop, monitor, lr_schedule]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9QwjzSdOTT5Y"
   },
   "source": [
    "4. Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "4xH3sWvIz_k5",
    "outputId": "1004d632-3755-4602-dea2-ddbddf9afe0e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-18 20:55:17.215162: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-03-18 20:55:17.216426: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2300015000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-18 20:55:17.866021: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-03-18 20:55:18.229965: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-03-18 20:55:19.147425: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256\n",
      "2022-03-18 20:55:19.181085: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2022-03-18 20:55:20.735047: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.83GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226/226 [==============================] - 117s 502ms/step - loss: 10.3984 - accuracy: 0.5392 - val_loss: 0.2426 - val_accuracy: 0.9178\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.91782, saving model to training_1/cp.ckpt\n",
      "Epoch 2/50\n",
      "226/226 [==============================] - 140s 613ms/step - loss: 0.0312 - accuracy: 0.9952 - val_loss: 0.0900 - val_accuracy: 0.9750\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.91782 to 0.97501, saving model to training_1/cp.ckpt\n",
      "Epoch 3/50\n",
      "226/226 [==============================] - 139s 609ms/step - loss: 0.0052 - accuracy: 0.9996 - val_loss: 0.0878 - val_accuracy: 0.9783\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.97501 to 0.97835, saving model to training_1/cp.ckpt\n",
      "Epoch 4/50\n",
      "226/226 [==============================] - 139s 610ms/step - loss: 0.0207 - accuracy: 0.9940 - val_loss: 0.1763 - val_accuracy: 0.9400\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.97835\n",
      "Epoch 5/50\n",
      "226/226 [==============================] - 110s 485ms/step - loss: 0.0922 - accuracy: 0.9718 - val_loss: 0.0860 - val_accuracy: 0.9739\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.97835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe2cf97f190>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_images, \n",
    "    validation_data=val_images, \n",
    "    epochs=50, # Fine tune\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9608/1829836213.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.save('Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n************************ COMPLETED ************************\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FishClassification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
