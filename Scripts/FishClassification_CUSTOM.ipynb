{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4km0ReLe1Dtr",
    "outputId": "95551279-0348-4a3e-8302-c633ac072e41"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import os\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working directory: /data\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/data')\n",
    "working_directory = os.getcwd()\n",
    "print(\"working directory:\", working_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Bym740s1nlG"
   },
   "source": [
    "1. Loading Data and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_image_df(folder):\n",
    "    test_image_dir = Path('fish_data/'+folder)\n",
    "    test_filepaths = list(test_image_dir.glob(r'*/*.*'))\n",
    "    test_labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], test_filepaths))\n",
    "\n",
    "    test_filepaths = pd.Series(test_filepaths, name='Filepath').astype(str)\n",
    "    test_labels = pd.Series(test_labels, name='Label')\n",
    "    test_image_df = pd.concat([test_filepaths, test_labels], axis=1)\n",
    "    return test_image_df\n",
    "\n",
    "test_df = make_image_df('Test')\n",
    "dev_df = make_image_df('Train_Val')\n",
    "total_df = pd.concat([dev_df, test_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Filepath            Label\n",
      "0           fish_data/Test/Black Sea Sprat/00023.png  Black Sea Sprat\n",
      "1           fish_data/Test/Black Sea Sprat/00005.png  Black Sea Sprat\n",
      "2           fish_data/Test/Black Sea Sprat/00003.png  Black Sea Sprat\n",
      "3           fish_data/Test/Black Sea Sprat/00009.png  Black Sea Sprat\n",
      "4  fish_data/Test/Black Sea Sprat/.ipynb_checkpoints  Black Sea Sprat\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(438, 2)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test_df.head())\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        Filepath            Label\n",
      "0  fish_data/Train_Val/Black Sea Sprat/00124.png  Black Sea Sprat\n",
      "1  fish_data/Train_Val/Black Sea Sprat/00960.png  Black Sea Sprat\n",
      "2  fish_data/Train_Val/Black Sea Sprat/00612.png  Black Sea Sprat\n",
      "3  fish_data/Train_Val/Black Sea Sprat/00365.png  Black Sea Sprat\n",
      "4  fish_data/Train_Val/Black Sea Sprat/00681.png  Black Sea Sprat\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9009, 2)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dev_df.head())\n",
    "dev_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        Filepath            Label\n",
      "0  fish_data/Train_Val/Black Sea Sprat/00124.png  Black Sea Sprat\n",
      "1  fish_data/Train_Val/Black Sea Sprat/00960.png  Black Sea Sprat\n",
      "2  fish_data/Train_Val/Black Sea Sprat/00612.png  Black Sea Sprat\n",
      "3  fish_data/Train_Val/Black Sea Sprat/00365.png  Black Sea Sprat\n",
      "4  fish_data/Train_Val/Black Sea Sprat/00681.png  Black Sea Sprat\n",
      "(9447, 2)\n"
     ]
    }
   ],
   "source": [
    "print(total_df.head())\n",
    "print(total_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df, test_df = train_test_split(total_df, test_size=0.1, train_size=0.9, shuffle=True, random_state=42)\n",
    "train_df, val_df = train_test_split(dev_df, test_size=0.2, train_size=0.8, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "0HFteFhy9SoO"
   },
   "outputs": [],
   "source": [
    "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255 # Could apply additional augmentation here\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "YCJxA9xS-94l",
    "outputId": "5aa0cea5-32f3-46c3-9310-cb737a003196"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6790 validated image filenames belonging to 9 classes.\n",
      "Found 1699 validated image filenames belonging to 9 classes.\n",
      "Found 941 validated image filenames belonging to 9 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/yes/envs/tensorflow/lib/python3.9/site-packages/keras_preprocessing/image/dataframe_iterator.py:279: UserWarning: Found 11 invalid image filename(s) in x_col=\"Filepath\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n",
      "/root/yes/envs/tensorflow/lib/python3.9/site-packages/keras_preprocessing/image/dataframe_iterator.py:279: UserWarning: Found 2 invalid image filename(s) in x_col=\"Filepath\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n",
      "/root/yes/envs/tensorflow/lib/python3.9/site-packages/keras_preprocessing/image/dataframe_iterator.py:279: UserWarning: Found 4 invalid image filename(s) in x_col=\"Filepath\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_images = image_generator.flow_from_dataframe(\n",
    "    dataframe = train_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "val_images = image_generator.flow_from_dataframe(\n",
    "    dataframe = val_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "test_images = image_generator.flow_from_dataframe(\n",
    "    dataframe = test_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0gM0NQ-wBJit",
    "outputId": "59e36998-f2ad-4241-dbdb-c3449823efd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training image shape: (224, 224, 3)\n",
      "Validation image shape: (224, 224, 3)\n",
      "Test image shape: (224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training image shape:\", train_images.image_shape)\n",
    "print(\"Validation image shape:\", val_images.image_shape)\n",
    "print(\"Test image shape:\", test_images.image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HpBab0rRIkjx",
    "outputId": "d83e7d17-01df-4b71-b7eb-657a4630f026"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Black Sea Sprat': 0,\n",
       " 'Gilt Head Bream': 1,\n",
       " 'Horse Mackerel': 2,\n",
       " 'Red Mullet': 3,\n",
       " 'Red Sea Bream': 4,\n",
       " 'Sea Bass': 5,\n",
       " 'Shrimp': 6,\n",
       " 'Striped Red Mullet': 7,\n",
       " 'Trout': 8}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zpssP4gHIrLE",
    "outputId": "1bc788b9-dcea-4e00-b67f-19eb3a0c5bca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Black Sea Sprat': 0,\n",
       " 'Gilt Head Bream': 1,\n",
       " 'Horse Mackerel': 2,\n",
       " 'Red Mullet': 3,\n",
       " 'Red Sea Bream': 4,\n",
       " 'Sea Bass': 5,\n",
       " 'Shrimp': 6,\n",
       " 'Striped Red Mullet': 7,\n",
       " 'Trout': 8}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_images.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WvNpGFsaNiRS",
    "outputId": "d75e9cf6-0dcb-4c33-9dfc-757692f120e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Black Sea Sprat': 0,\n",
       " 'Gilt Head Bream': 1,\n",
       " 'Horse Mackerel': 2,\n",
       " 'Red Mullet': 3,\n",
       " 'Red Sea Bream': 4,\n",
       " 'Sea Bass': 5,\n",
       " 'Shrimp': 6,\n",
       " 'Striped Red Mullet': 7,\n",
       " 'Trout': 8}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "RKpgdmcbw7ZS"
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, Input, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y8tJFnmZxE_Q"
   },
   "source": [
    "2. Defining VGG16 (CNN) Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pB_UJG23NlUj",
    "outputId": "973be7af-8041-4b27-a8e0-8862d2252ca3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 222, 222, 128)     3584      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 111, 111, 128)     0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 111, 111, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 109, 109, 64)      73792     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 54, 54, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 186624)            0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               47776000  \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 9)                 2313      \n",
      "=================================================================\n",
      "Total params: 47,921,481\n",
      "Trainable params: 47,921,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input = Input(shape =(224,224,3))\n",
    "l1 = Conv2D(filters=128, kernel_size=(3, 3), activation='relu')(input)\n",
    "l2 = MaxPool2D(2,2)(l1)\n",
    "l3 = Dropout(0.2)(l2)\n",
    "\n",
    "# Regularizing using penalty instead of dropout (want to maintain feature extraction capabilities)\n",
    "l4 = Conv2D(filters=64, kernel_size=(3,3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l2=0.001))(l3) \n",
    "l5 = MaxPool2D(2,2)(l4)\n",
    "l6 = Flatten()(l5)\n",
    "\n",
    "l7 = Dense(256, activation='relu')(l6)\n",
    "l8 = Dropout(0.2)(l7) # Only change after 94.9% test accuracy training run\n",
    "l9 = Dense(256, activation='relu')(l8)\n",
    "l10 = Dropout(0.2)(l9) # Only change after 94.9% test accuracy training run\n",
    "output = Dense(9, activation='softmax')(l10)\n",
    "\n",
    "model = Model (inputs=input, outputs =output)\n",
    "model.compile(\n",
    "    optimizer='adam', # Starting learning rate of 0.001 (default parameter)\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7jg-ixS3xn0e"
   },
   "source": [
    "3. Defining Schedulers and Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "sKzgcZxvxnf1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 10) # Fine tune\n",
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "monitor = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, monitor='val_loss',\n",
    "                                             verbose=1,save_best_only=True,\n",
    "                                             save_weights_only=True,\n",
    "                                             mode='min') # Only saves the best model (so far) in terms of min validation loss\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch%10 == 0 and epoch!= 0:\n",
    "        lr = lr/1.2\n",
    "    return lr\n",
    "\n",
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(scheduler,verbose = 0)\n",
    "lr_schedule_on_plateau = ReduceLROnPlateau(monitor='val_loss', mode='min', factor=0.1, patience=5, min_lr=0.000001, verbose=1)\n",
    "callbacks = [early_stop, monitor, lr_schedule_on_plateau,lr_schedule]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9QwjzSdOTT5Y"
   },
   "source": [
    "4. Training Model - run in .py format on cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "4xH3sWvIz_k5",
    "outputId": "1004d632-3755-4602-dea2-ddbddf9afe0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "213/213 [==============================] - 123s 575ms/step - loss: 2.2015 - accuracy: 0.4024 - val_loss: 0.5507 - val_accuracy: 0.8264\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.55074, saving model to training_1/cp.ckpt\n",
      "Epoch 2/50\n",
      "213/213 [==============================] - 109s 513ms/step - loss: 0.2979 - accuracy: 0.9177 - val_loss: 0.2720 - val_accuracy: 0.9229\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.55074 to 0.27203, saving model to training_1/cp.ckpt\n",
      "Epoch 3/50\n",
      "213/213 [==============================] - 108s 504ms/step - loss: 0.0942 - accuracy: 0.9851 - val_loss: 0.2470 - val_accuracy: 0.9247\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.27203 to 0.24697, saving model to training_1/cp.ckpt\n",
      "Epoch 4/50\n",
      "213/213 [==============================] - 107s 503ms/step - loss: 0.0766 - accuracy: 0.9891 - val_loss: 0.2086 - val_accuracy: 0.9453\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.24697 to 0.20862, saving model to training_1/cp.ckpt\n",
      "Epoch 5/50\n",
      "213/213 [==============================] - 107s 501ms/step - loss: 0.0512 - accuracy: 0.9955 - val_loss: 0.2044 - val_accuracy: 0.9500\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.20862 to 0.20441, saving model to training_1/cp.ckpt\n",
      "Epoch 6/50\n",
      "213/213 [==============================] - 107s 502ms/step - loss: 0.0599 - accuracy: 0.9908 - val_loss: 0.2367 - val_accuracy: 0.9364\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.20441\n",
      "Epoch 7/50\n",
      "213/213 [==============================] - 107s 504ms/step - loss: 0.0580 - accuracy: 0.9935 - val_loss: 0.2068 - val_accuracy: 0.9511\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.20441\n",
      "Epoch 8/50\n",
      "213/213 [==============================] - 108s 507ms/step - loss: 0.0412 - accuracy: 0.9954 - val_loss: 0.2372 - val_accuracy: 0.9364\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.20441\n",
      "Epoch 9/50\n",
      "213/213 [==============================] - 107s 502ms/step - loss: 0.0402 - accuracy: 0.9960 - val_loss: 0.2780 - val_accuracy: 0.9370\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.20441\n",
      "Epoch 10/50\n",
      "111/213 [==============>...............] - ETA: 41s - loss: 0.0317 - accuracy: 0.9965\n",
      "model training terminated\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    history = model.fit(\n",
    "        train_images, \n",
    "        validation_data=val_images, \n",
    "        epochs=50, # Fine tune\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nmodel training terminated\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4185/3958911168.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'history1.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "np.save('history.npy', history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Loading/Saving Best Model and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f14a77c1160>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All training results {'loss': [1.2918709516525269, 0.30588680505752563, 0.1398799866437912, 0.0918986052274704, 0.0747467502951622, 0.05734184756875038, 0.05725032091140747, 0.072073794901371, 0.046092379838228226, 0.04909295216202736, 0.027461392804980278, 0.024308525025844574, 0.020618436858057976, 0.01864658296108246, 0.017741279676556587, 0.01764005608856678, 0.01673857495188713, 0.016180915758013725, 0.01548372209072113, 0.015170665457844734, 0.015041062608361244, 0.014333194121718407, 0.013551276177167892, 0.013165684416890144, 0.013172327540814877, 0.012194763869047165, 0.012850886210799217, 0.011144140735268593, 0.010956073179841042, 0.010202297009527683, 0.01004001498222351, 0.00980854406952858, 0.009938756003975868, 0.009602274745702744, 0.009361282922327518, 0.0092219989746809], 'accuracy': [0.5773195624351501, 0.9141384363174438, 0.9702503681182861, 0.9846833348274231, 0.9883652329444885, 0.9924889802932739, 0.9929307699203491, 0.9865979552268982, 0.9938144087791443, 0.9927834868431091, 0.9982327222824097, 0.9974963068962097, 0.99955815076828, 0.99970543384552, 1.0, 0.99955815076828, 0.99985271692276, 1.0, 1.0, 1.0, 0.99970543384552, 0.99985271692276, 1.0, 1.0, 0.99970543384552, 0.99985271692276, 0.99955815076828, 1.0, 0.99970543384552, 1.0, 0.99985271692276, 0.99985271692276, 0.99970543384552, 1.0, 0.99985271692276, 1.0], 'val_loss': [0.5122151970863342, 0.29289162158966064, 0.2454271912574768, 0.16263175010681152, 0.17997534573078156, 0.15314677357673645, 0.13499990105628967, 0.17987768352031708, 0.2239357829093933, 0.20245425403118134, 0.14819158613681793, 0.1834457814693451, 0.11428215354681015, 0.11542539298534393, 0.11802039295434952, 0.10906194150447845, 0.10807915776968002, 0.1079614907503128, 0.10485862195491791, 0.10769785940647125, 0.10317286103963852, 0.09971693158149719, 0.098015695810318, 0.09708284586668015, 0.09571054577827454, 0.09205737709999084, 0.09630084037780762, 0.09229335933923721, 0.09435724467039108, 0.09282678365707397, 0.10711389034986496, 0.10106062889099121, 0.09574232995510101, 0.09510141611099243, 0.09473992884159088, 0.09425243735313416], 'val_accuracy': [0.8481459617614746, 0.9146556854248047, 0.9352560043334961, 0.9593878984451294, 0.9582107067108154, 0.9564449787139893, 0.9635079503059387, 0.9564449787139893, 0.9317245483398438, 0.9470276832580566, 0.9623307585716248, 0.9582107067108154, 0.967628002166748, 0.9658622741699219, 0.9658622741699219, 0.968805193901062, 0.968805193901062, 0.969393789768219, 0.9711595177650452, 0.9699823260307312, 0.9711595177650452, 0.9729252457618713, 0.9729252457618713, 0.9741024374961853, 0.9776338934898376, 0.9752795696258545, 0.9723366498947144, 0.9741024374961853, 0.9735138416290283, 0.9746909737586975, 0.968216598033905, 0.969393789768219, 0.9699823260307312, 0.9699823260307312, 0.969393789768219, 0.9699823260307312], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.00083333335, 8.333333e-05, 8.333333e-05, 8.333333e-05, 8.333333e-05, 8.333333e-05, 8.333333e-05, 8.333333e-05, 8.333333e-05, 8.333333e-05, 6.9444446e-05, 6.9444446e-05, 6.9444446e-05, 6.9444446e-05, 6.9444446e-05, 6.9444446e-05, 6.9444446e-05, 6.9444446e-05, 6.9444446e-05, 6.9444446e-05, 5.7870375e-06, 5.7870375e-06, 5.7870375e-06, 5.7870375e-06, 5.7870375e-06, 1e-06]}\n"
     ]
    }
   ],
   "source": [
    "history=np.load('history.npy', allow_pickle='TRUE').item() # Get standard scalar object\n",
    "print(\"All training results\", history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Training Results:\n",
      "\n",
      "Training Loss: 0.012194763869047165\n",
      "Validation Loss: 0.09205737709999084\n",
      "Training Accuracy: 0.99985271692276\n",
      "Validation Accuracy: 0.9752795696258545\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_loss_indx= np.argmin(history.get('val_loss'))\n",
    "print(\"Best Training Results:\\n\")\n",
    "print(\"Training Loss: {}\\nValidation Loss: {}\\nTraining Accuracy: {}\\nValidation Accuracy: {}\\n\".format(history.get('loss')[val_loss_indx], history.get('val_loss')[val_loss_indx], \n",
    "              history.get('accuracy')[val_loss_indx], history.get('val_accuracy')[val_loss_indx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 15s 488ms/step - loss: 0.0755 - accuracy: 0.9773\n",
      "Categorical Cross Entropy: 0.08670\n",
      "Test Accuracy: 97.45%\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_images, verbose=1)\n",
    "\n",
    "print(\"Categorical Cross Entropy: {:.5f}\".format(results[0]))\n",
    "print(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FishClassification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
